MLG10301 | Introduction to Machine Learning | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=10301&SEMESTER=S19 | instructors:Gormley, Matthew prereq:(15122) and (21128 or 15151 or 21127) and (36217 or 21325 or 36225 or 36218 or 15359) description:Machine Learning (ML) develops computer programs that automatically improve their performance through experience. This includes learning many types of tasks based on many types of experience, e.g. spotting high-risk medical patients, recognizing speech, classifying text documents, detecting credit card fraud, or driving autonomous vehicles. 10301 covers all or most of: concept learning, decision trees, neural networks, linear learning, active learning, estimation  the bias-variance tradeoff, hypothesis testing, Bayesian learning, the MDL principle, the Gibbs classifier, Naive Bayes, Bayes Nets  Graphical Models, the EM algorithm, Hidden Markov Models, K-Nearest-Neighbors and nonparametric learning, reinforcement learning, bagging, boosting and discriminative training. Grading will be based on weekly or biweekly assignments (written and/or programming), a midterm, a final exam. 10301 is recommended for undergraduates who are not SCS majors. (SCS majors should instead take 10315.) Prerequisites (strictly enforced): strong quantitative aptitude, college probability  statistics course, and programming proficiency. For learning to apply ML practically  effectively, without the above prerequisites, consider 11344/05834 instead. You can evaluate your ability to take the course via a self-assessment exam (http://bit.ly/2fkddDN). Also, be sure to read the ML course comparison (http://bit.ly/2eV3UaD).
MLG10315 | Introduction to Machine Learning (Undergrad) | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=10315&SEMESTER=S19 | instructors:Balcan, Maria prereq:(15122) and (21127 or 21128 or 15151) and (21325 or 36217 or 36218 or 36225 or 15359) description:Machine learning is subfield of computer science with the goal of exploring, studying, and developing learning systems, methods, and algorithms that can improve their performance with learning from data. This course is designed to give undergraduate students a one-semester-long introduction to the main principles, algorithms, and applications of machine learning and is specifically designed for the SCS undergrad majors. The topics of this course will be in part parallel with those covered in the graduate machine learning courses (10-715, 10-701, 10-601), but with a greater emphasis on applications and case studies in machine learning.  After completing the course, students will be able to:  *select and apply an appropriate supervised learning algorithm for classification problems (e.g., naive Bayes, perceptron, support vector machine, logistic regression).   *select and apply an appropriate supervised learning algorithm for regression problems (e.g., linear regression, ridge regression).  *recognize different types of unsupervised learning problems, and select and apply appropriate algorithms (e.g., clustering, linear and nonlinear dimensionality reduction).   *work with probabilities (Bayes rule, conditioning, expectations, independence), linear algebra (vector and matrix operations, eigenvectors, SVD), and calculus (gradients, Jacobians) to derive machine learning methods such as linear regression, naive Bayes, and principal components analysis.   *understand machine learning principles such as model selection, overfitting, and underfitting, and techniques such as cross-validation and regularization.   *implement machine learning algorithms such as logistic regression via stochastic gradient descent, linear regression (using a linear algebra toolbox), perceptron, or k-means clustering.   *run appropriate supervised and unsupervised learning algorithms on real and synthetic data sets and interpret the results.
MLG10335 | Art and Machine Learning | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=10335&SEMESTER=S19 | instructors:Kang, Eun Su description:Ars, the Latin origin of the word art, means Art and Science. These two fields, which have been separated for a long time, are joining back together in many areas. One of those junctions is where Art and Machine Learning meet. Art in recent years has been moving forward along with the rise of new technologies and scientific discoveries. Machine Learning (ML) is one of the most cutting edge advancements in Computer Science. The popularity and accessibility of frameworks such as Googles Deep Dream system, Pikazo the neural style transfer, Kulitta AI Music Generation Framework, Deep Minds WaveNet, Sonys Flow Machines, and recurrent neural network based language models brought great attention to the marriage of Art and ML methods. The number of ML applications that mimic famous artworks, e.g. The Next Rembrandt project, or even create original artworks such as the robot artist TAIDAs paintings, is rapidly growing. Increasing number of artists are also attempting to use ML methods in their artworks.    This course is project-based and aims to introduce the crossroad of Art and Machine Learning to the broad range of students including both Art and Computer Science majors. We will offer the knowledge of examples, technologies, and issues that connect Art and Machine Learning to the students. Students will study example codes and produce creative applications/artworks using ML methods. Students do not need to have pre-existing knowledge of Machine Learning or experience of Art practice. Students are required to have basic understanding of Python and be open-minded, for example, open to learn the necessary mathematical background and open to discussions on conceptual development and artistic value of their projects.
MLG10401 | Introduction to Machine Learning (Undergrad)This Section Cancelled | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=10401&SEMESTER=F18 | instructors:Di Caro, Gianni prereq:(15122) and (21127 or 15151 or 21128) and (36217 or 36218 or 36225 or 21325 or 15359) description:Machine learning is subfield of computer science with the goal of exploring, studying, and developing learning systems, methods, and algorithms that can improve their performance with learning from data. This course is designed to give undergraduate students a one-semester-long introduction to the main principles, algorithms, and applications of machine learning.   Topics. The topics of this course will be in part parallel with those covered in the graduate machine learning courses (10-715, 10-701, 10-601), but with a greater emphasis on applications and case studies in machine learning.  After completing the course, students will be able to:  *select and apply an appropriate supervised learning algorithm for classification problems (e.g., naive Bayes, perceptron, support vector machine, logistic regression).   *select and apply an appropriate supervised learning algorithm for regression problems (e.g., linear regression, ridge regression).  *recognize different types of unsupervised learning problems, and select and apply appropriate algorithms (e.g., clustering, linear and nonlinear dimensionality reduction).   *work with probabilities (Bayes rule, conditioning, expectations, independence), linear algebra (vector and matrix operations, eigenvectors, SVD), and calculus (gradients, Jacobians) to derive machine learning methods such as linear regression, naive Bayes, and principal components analysis.   *understand machine learning principles such as model selection, overfitting, and underfitting, and techniques such as cross-validation and regularization.   *implement machine learning algorithms such as logistic regression via stochastic gradient descent, linear regression (using a linear algebra toolbox), perceptron, or k-means clustering.   *run appropriate supervised and unsupervised learning algorithms on real and synthetic data sets and interpret the results.
MLG10403 | Deep Reinforcement Learning &amp; Control | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=10403&SEMESTER=S19 | instructors:Fragkiadaki, Aikaterini prereq:10301 or 10315 or 10401 or 10601 or 10701 description:TBD
MLG10405 | Machine Learning with Large Datasets (Undergraduate) | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=10405&SEMESTER=S19 | instructors:Poczos, Barnabas prereq:15211 or 15210 or 15214 or 17214 description:Large datasets are difficult to work with for several reasons. They are difficult to visualize, and it is difficult to understand what sort of errors and biases are present in them. They are computationally expensive to process, and often the cost of learning is hard to predict - for instance, and algorithm that runs quickly in a dataset that fits in memory may be exorbitantly expensive when the dataset is too large for memory. Large datasets may also display qualitatively different behavior in terms of which learning methods produce the most accurate predictions.  This course is intended to provide a student practical knowledge of, and experience with, the issues involving large datasets. Among the issues considered are: scalable learning techniques, such as streaming machine learning techniques; parallel infrastructures such as map-reduce; practical techniques for reducing the memory requirements for learning methods, such as feature hashing and Bloom filters; and techniques for analysis of programs in terms of memory, disk usage, and (for parallel methods) communication complexity.  The class will include programming assignments, and a one-month short project chosen by the student. The project will be designed to compare the scalability of variant learning algorithms on datasets.  An introductory course in machine learning, like 10-401, 10-601, or 10-701, is a prerequisite or a co-requisite. If you plan to take this course and the introductory machine learning course concurrently please tell the instructor. The course will include several substantial programming assignments, so an additional prerequisite is 15-211, or 15-214, or comparable familiarity with Java and good programming skills.
MLG10500 | Senior Research Project | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=10500&SEMESTER=S19 | instructors:Gormley, Matthew description:Register for this course if you are minoring in Machine Learning. This course is intended for research with a faculty member that would count towards the minor.
MLG10520 | Independent Study | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=10520&SEMESTER=S19 | instructors:Gormley, Matthew description:Independent Study intended to work on research with a Machine Learning faculty member.
MLG10600 | Mathematical background for Machine LearningThis Section Cancelled | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=10600&SEMESTER=F18 | instructors:Gormley, Matthew description:This course provides a place for students to practice the necessary mathematical background for further study in machine learning -- particularly for taking 10-601 and 10-701. Topics covered include probability, linear algebra (inner product spaces, linear operators), multivariate differential calculus, optimization, and likelihood functions. The course assumes some background in each of the above, but will review and give practice in each. (It does not provide from-scratch coverage of all of the above, which would be impossible in a course of this length.) Some coding will be required: the course will provide practice with translating the above mathematical concepts into concrete programs. This course supersedes the two mini-courses 10-606 and 10-607.
MLG10601 | Introduction to Machine Learning (Master's) | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=10601&SEMESTER=S19 | instructors:Gormley, Matthew prereq:(15122) and (21127 or 15151 or 21128) and (15359 or 36225 or 21325 or 36217 or 36218) description:Machine Learning (ML) develops computer programs that automatically improve their performance through experience. This includes learning many types of tasks based on many types of experience, e.g. spotting high-risk medical patients, recognizing speech, classifying text documents, detecting credit card fraud, or driving autonomous vehicles. 10601 covers all or most of: concept learning, decision trees, neural networks, linear learning, active learning, estimation  the bias-variance tradeoff, hypothesis testing, Bayesian learning, the MDL principle, the Gibbs classifier, Naive Bayes, Bayes Nets  Graphical Models, the EM algorithm, Hidden Markov Models, K-Nearest-Neighbors and nonparametric learning, reinforcement learning, bagging, boosting and discriminative training. Grading will be based on weekly or biweekly assignments (written and/or programming), a midterm, a final exam. 10601 is recommended for CS Seniors  Juniors, quantitative Masters students,  non-MLD PhD students. Prerequisites (strictly enforced): strong quantitative aptitude, college probability  statistics course, and programming proficiency. For learning to apply ML practically  effectively, without the above prerequisites, consider 11344/05834 instead. You can evaluate your ability to take the course via a self-assessment exam (http://bit.ly/2fkddDN). Also, be sure to read the ML course comparison (http://bit.ly/2eV3UaD).
MLG10605 | Machine Learning with Large Datasets | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=10605&SEMESTER=S19 | instructors:Poczos, Barnabas prereq:15214 or 15210 or 17214 description:Large datasets are difficult to work with for several reasons. They are difficult to visualize, and it is difficult to understand what sort of errors and biases are present in them. They are computationally expensive to process, and often the cost of learning is hard to predict - for instance, and algorithm that runs quickly in a dataset that fits in memory may be exorbitantly expensive when the dataset is too large for memory. Large datasets may also display qualitatively different behavior in terms of which learning methods produce the most accurate predictions.  This course is intended to provide a student practical knowledge of, and experience with, the issues involving large datasets. Among the issues considered are: scalable learning techniques, such as streaming machine learning techniques; parallel infrastructures such as map-reduce; practical techniques for reducing the memory requirements for learning methods, such as feature hashing and Bloom filters; and techniques for analysis of programs in terms of memory, disk usage, and (for parallel methods) communication complexity.  The class will include programming assignments, and a one-month short project chosen by the student. The project will be designed to compare the scalability of variant learning algorithms on datasets.  An introductory course in machine learning, like 10-601 or 10-701, is a prerequisite or a co-requisite. If you plan to take this course and 10-601 concurrently please tell the instructor.  The course will include several substantial programming assignments, so an additional prerequisite is 15-211, or 15-214, or comparable familiarity with Java and good programming skills.
MLG10606 | Mathematical Foundations for Machine Learning | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=10606&SEMESTER=F18 | instructors:Gormley, Matthew description:This course provides a place for students to practice the necessary mathematical background for further study in machine learning. Topics covered include probability (random variables, modeling with continuous and discrete distributions), linear algebra (inner product spaces, linear operators), and multivariate differential calculus (partial derivatives, matrix differentials). The course assumes some background in each of the above, but will review and give practice in each. (It does not provide from-scratch coverage of all of the above, which would be impossible in a course of this length.) Some coding will be required: the course will provide practice with translating the above mathematical concepts into concrete programs.   This course is one of two minis intended to prepare students for further study in machine learning -- particularly for taking 10-601 and 10-701. One of the courses 10-606 focuses on mathematical background, and the other course 10-607 focuses on computational background. Most students take both mini courses, but this is not required. 10-606 is not a prerequisite of 10-607.
MLG10607 | Computational Foundations for Machine Learning | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=10607&SEMESTER=F18 | instructors:Gormley, Matthew description:This course provides a place for students to practice the necessary computational background for further study in machine learning. Topics covered include computational complexity, analysis of algorithms, proof techniques, optimization, dynamic programming, recursion, and data structures. The course assumes some background in each of the above, but will review and give practice in each. (It does not provide from-scratch coverage of all of the above, which would be impossible in a course of this length.) Some coding will be required: the course will provide practice with translating the above computational concepts into concrete programs.  This course is one of two minis intended to prepare students for further study in machine learning -- particularly for taking 10-601 and 10-701. One of the courses 10-606 focuses on mathematical background, and the other course 10-607 focuses on computational background. Most students take both mini courses, but this is not required. 10-606 is not a prerequisite of 10-607.
MLG10611 | MS DAP Research | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=10611&SEMESTER=F18 | instructors:Balcan, MariaSalakhutdinov, Ruslan description:This course is for ML Masters students to work on research with their advisor for the Data Analysis Project.
MLG10615 | Art and Machine Learning | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=10615&SEMESTER=S19 | instructors:Kang, Eun Su description:Ars, the Latin origin of the word art, means Art and Science. These two fields, which have been separated for a long time, are joining back together in many areas. One of those junctions is where Art and Machine Learning meet. Art in recent years has been moving forward along with the rise of new technologies and scientific discoveries. Machine Learning (ML) is one of the most cutting edge advancements in Computer Science. The popularity and accessibility of frameworks such as Googles Deep Dream system, Pikazo the neural style transfer, Kulitta AI Music Generation Framework, Deep Minds WaveNet, Sonys Flow Machines, and recurrent neural network based language models brought great attention to the marriage of Art and ML methods. The number of ML applications that mimic famous artworks, e.g. The Next Rembrandt project, or even create original artworks such as the robot artist TAIDAs paintings, is rapidly growing. Increasing number of artists are also attempting to use ML methods in their artworks.    This course is project-based and aims to introduce the crossroad of Art and Machine Learning to the broad range of students including both Art and Computer Science majors. We will offer the knowledge of examples, technologies, and issues that connect Art and Machine Learning to the students. Students will study example codes and produce creative applications/artworks using ML methods. Students do not need to have pre-existing knowledge of Machine Learning or experience of Art practice. Students are required to have basic understanding of Python and be open-minded, for example, open to learn the necessary mathematical background and open to discussions on conceptual development and artistic value of their projects. Students should have a basic understanding of Python.
MLG10620 | Independent Study: Research | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=10620&SEMESTER=S19 | instructors:Balcan, MariaSalakhutdinov, Ruslan description:Independent Study intended to work on research with a Machine Learning faculty member.
MLG10697 | Reading and Research | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=10697&SEMESTER=S19 | instructors:Balcan, MariaSalakhutdinov, Ruslan description:Course for MS students to work with their advisor on research
MLG10701 | Introduction to Machine Learning (PhD) | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=10701&SEMESTER=S19 | instructors:Wehbe, Leila prereq:(15122) and (15151 or 21127 or 21128) and (36218 or 36217 or 36225 or 15359 or 21325) description:Machine learning studies the question How can we build computer programs that automatically improve their performance through experience?   This includes learning to perform many types of tasks based on many types of experience.  For example, it includes robots learning to better navigate based on experience gained by roaming their environments, medical decision aids that learn to predict which therapies work best for which diseases based on data mining of historical health records, and speech recognition systems that learn to better understand your speech based on experience listening to you.  This course is designed to give PhD students a thorough grounding in the methods, mathematics and algorithms needed to do research and applications in machine learning. Students entering the class with a pre-existing working knowledge of probability, statistics and algorithms will be at an advantage, but the class has been designed so that anyone with a strong numerate background can catch up and fully participate. You can evaluate your ability to take the course via a self-assessment exam that will be made available to you  after you register.  If you are interested in this topic, but are not a PhD student, or are a PhD student not specializing in machine learning, you might consider the masters level course on Machine Learning, 10-601.  This class may be appropriate for MS and undergrad students who are interested in the theory and algorithms behind ML.  You can evaluate your ability to take the course via a self-assessment exam at: https://qna-app.appspot.com/view.html?aglzfnFuYS1hcHByGQsSDFF1ZXN0aW9uTGlzdBiAgICgpO-KCgw ML course comparison: https://docs.google.com/document/d/1Y0Jx_tcINWQrWJx31WGEQSsUs059OUMmPIVSeyxNdeM/edit
MLG10703 | Deep Reinforcement Learning &amp; Control | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=10703&SEMESTER=F18 | instructors:Fragkiadaki, AikateriniMitchell, Tom prereq:10601 or 10715 or 10701 description:This course will cover latest advances in Reinforcement Learning and Control, such as, deep Q learning, actor-critic methods, learning and planning, concurrent trajectory optimization and policy learning, inverse reinforcement learning, hierarchical reinforcement learning methods, forward predictive models, deep model predictive control, exploration strategies, adaptive control, applications to deep robotic learning. By the end of the course you should be able to: 1) code up a suitable reinforcement learning method in simulation or on robotic platform for a task 2) identify what are easy and hard problems in RL and learning for robotics  The course will have a final project which will involve design of a reinforcement learning method in simulation or robotic platform. The homeworks will be in OpenAI gym. Pre-requisites: Students should have a basic background in algorithms, linear algebra, machine Learning, deep learning.
MLG10707 | Topics in Deep Learning | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=10707&SEMESTER=S19 | instructors:Salakhutdinov, Ruslan prereq:10401 or 10601 or 10701 or 10715 description:Building intelligent machines that are capable of extracting meaningful representations from high-dimensional data lies at the core of solving many AI related tasks. In the past few years, researchers across many different communities, from applied statistics to engineering, computer science and neuroscience, have developed deep (hierarchical) models -- models that are composed of several layers of nonlinear processing. An important property of these models is that they can learn useful representations by re-using and combining intermediate concepts, allowing these models to be successfully applied in a wide variety of domains, including visual object recognition, information retrieval, natural language processing, and speech perception.  This is an advanced graduate course, designed for Masters and Ph.D. level students, and will assume a reasonable degree of mathematical maturity. The goal of this course is to introduce students to the recent and exciting developments of various deep learning methods. Some topics to be covered include: restricted Boltzmann machines (RBMs) and their multi-layer extensions Deep Belief Networks and Deep Boltzmann machines; sparse coding, autoencoders, variational autoencoders, convolutional neural networks, recurrent neural networks, generative adversarial networks, and attention-based models with applications in vision, NLP, and multimodal learning. We will also address mathematical issues, focusing on efficient large-scale optimization methods for inference and learning, as well as training density models with intractable partition functions.  Prerequisite: ML: 10-701 or 10-715, and strong programming skills.
MLG10708 | Probabilistic Graphical Models | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=10708&SEMESTER=S19 | instructors:Xing, Eric prereq:10715 or 10701 description:Many of the problems in artificial intelligence, statistics, computer systems, computer vision, natural language processing, and computational biology, among many other fields, can be viewed as the search for a coherent global conclusion from local information. The probabilistic graphical models framework provides an unified view for this wide range of problems, enabling efficient inference, decision-making and learning in problems with a very large number of attributes and huge datasets. This graduate-level course will provide you with a strong foundation for both applying graphical models to complex problems and for addressing core research topics in graphical models.  The class will cover three aspects: The core representation, including Bayesian and Markov networks, and dynamic Bayesian networks; probabilistic inference algorithms, both exact and approximate; and, learning methods for both the parameters and the structure of graphical models. Students entering the class should have a pre-existing working knowledge of probability, statistics, and algorithms, though the class has been designed to allow students with a strong numerate background to catch up and fully participate.  It is expected that after taking this class, the students should have obtain sufficient working knowledge of multi-variate probabilistic modeling and inference for practical applications, should be able to formulate and solve a wide range of problems in their own domain using GM, and can advance into more specialized technical literature by themselves.  Students are required to have successfully completed 10701 or 10715, or an equivalent class.
MLG10715 | Advanced Introduction to Machine Learning | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=10715&SEMESTER=F18 | instructors:Balcan, Maria description:The rapid improvement of sensory techniques and processor speed, and the availability of inexpensive massive digital storage, have led to a growing demand for systems that can automatically comprehend and mine massive and complex data from diverse sources.  Machine Learning is becoming the primary mechanism by which information is extracted from Big Data, and a primary pillar that Artificial Intelligence is built upon.  This course is designed for Ph.D. students whose primary field of study is machine learning, or who intend to make machine learning methodological research a main focus of their thesis.  It will give students a thorough grounding in the algorithms, mathematics, theories, and insights needed to do in-depth research and applications in machine learning. The topics of this course will in part parallel those covered in the general graduate machine learning course (10-701), but with a greater emphasis on depth in theory and algorithms.   The course will also include additional advanced topics such as privacy in machine learning, interactive learning, reinforcement learning, online learning,  Bayesian nonparametrics, and additional material on graphical models.  Students entering the class are expected to have a pre-existing strong working knowledge of algorithms, linear algebra, probability, and statistics.  If you are interested in this topic, but do not have the required background or are not planning to work on a PhD thesis with machine learning as the main focus, you might consider the general graduate Machine Learning course (10-701) or the Masters-level Machine Learning course (10-601). ML course comparison: https://goo.gl/mmR2eL
MLG10716 | Advanced Machine Learning: Theory and Methods | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=10716&SEMESTER=S19 | instructors:Ravikumar, Pradeep prereq:(10701 or 10715) and (36700 or 36705) description:Advanced Machine Learning: Theory and Methods is a graduate level course introducing the theoretical foundations of modern machine learning, as well as advanced methods and frameworks used in modern machine learning. The course assumes that students have taken graduate level introductory courses in machine learning (Introduction to Machine Learning, 10-701 or 10-715), as well as Statistics (Intermediate Statistics, 36-700 or 36-705). The course treats both the art of designing good learning algorithms, as well as the science of analyzing an algorithms computational and statistical properties and performance guarantees. Theorems are presented together with practical aspects of methodology and intuition to help students develop tools for selecting appropriate methods and approaches to problems in their own research. We will cover theoretical foundation topics such as computational and statistical convergence rates, minimax estimation, and concentration of measure. We will also cover advanced machine learning methods such as nonparametric density estimation, nonparametric regression, and Bayesian estimation, as well as advanced frameworks such as privacy, causality, and stochastic learning algorithms.
MLG10718 | Data Analysis | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=10718&SEMESTER=S19 | instructors:Talwalkar, Ameet description:In this course students will gain exposure to practical aspects of machine learning and data analysis. Through a mix of lectures, student presentations, and assignments, the course will cover the various stages in modern data analysis pipelines, as well other relevant applied learning topics, including experimental design for properly evaluating statistical methods, modern societal problems related to FATE (fairness, accountability, transparency, ethics), and ML engineering best-practices.
MLG10725 | Convex Optimization | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=10725&SEMESTER=F18 | instructors:Tibshirani, Ryan description:Nearly every problem in machine learning can be formulated as the optimization of some function, possibly under some set of constraints. This universal reduction may seem to suggest that such optimization tasks are intractable. Fortunately, many real world problems have special structure, such as convexity, smoothness, separability, etc., which allow us to formulate optimization problems that can often be solved efficiently. This course is designed to give a graduate-level student a thorough grounding in the formulation of optimization problems that exploit such structure, and in efficient solution methods for these problems. The main focus is on the formulation and solution of convex optimization problems, though we will discuss some recent advances in nonconvex optimization. These general concepts will also be illustrated through applications in machine learning and statistics. Students entering the class should have a pre-existing working knowledge of algorithms, though the class has been designed to allow students with a strong numerate background to catch up and fully participate. Though not required, having taken 10-701 or an equivalent machine learning or statistical modeling class is strongly encouraged, as we will use applications in machine learning and statistics to demonstrate the concepts we cover in class. Students will work on an extensive optimization-based project throughout the semester.
MLG10805 | Machine Learning with Large Datasets | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=10805&SEMESTER=F18 | instructors:Poczos, Barnabas prereq:15214 or 15210 or 17214 description:Large datasets are difficult to work with for several reasons. They are difficult to visualize, and it is difficult to understand what sort of errors and biases are present in them. They are computationally expensive to process, and often the cost of learning is hard to predict - for instance, and algorithm that runs quickly in a dataset that fits in memory may be exorbitantly expensive when the dataset is too large for memory. Large datasets may also display qualitatively different behavior in terms of which learning methods produce the most accurate predictions.  This course is intended to provide a student practical knowledge of, and experience with, the issues involving large datasets. Among the issues considered are: scalable learning techniques, such as streaming machine learning techniques; parallel infrastructures such as map-reduce; practical techniques for reducing the memory requirements for learning methods, such as feature hashing and Bloom filters; and techniques for analysis of programs in terms of memory, disk usage, and (for parallel methods) communication complexity.  An introductory course in machine learning, like 10-601 or 10-701, is a prerequisite or a co-requisite.     The class will include programming assignments, presentation of relevant research papers to the class, and a research project chosen by the student, to be presented to the class, and written up in a conference-paper format.     10-805 will share lectures with 10-605, but 10-805 students need to make class presentations and complete a research project, and will do fewer programming assignments, so 10-805 students are expected to be capable of surveying recent literature and conducting research. Four lecture sessions for 10-605 will also be reserved for 10-805 students presentations.    If there is sufficient interest we will introduce a mechanism for 10-605 students to collaborate of 10-805 students on projects.
MLG10910 | PhD DAP Research | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=10910&SEMESTER=F18 | instructors:Singh, Aarti description:Course for ML PhD students to complete their Data Analysis Project research. Register for this course in the semester you plan to present your DAP.
MLG10920 | Graduate Reading and Research | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=10920&SEMESTER=S19 | instructors:Poczos, Barnabas description:This course is for graduate students to work on research with their advisor before they propose their thesis topic.
MLG10930 | Dissertation Research | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=10930&SEMESTER=S19 | instructors:Poczos, Barnabas description:This course is for graduate students to work on their dissertation research after they have proposed their thesis topic.
MLG10935 | Practicum | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=10935&SEMESTER=S19 | instructors:Poczos, Barnabas description:This course is intended for you to gain industry research experience while using the skills you have learned in the ML curriculum and will count towards the research units for your degree.
MLG10940 | Independent Study | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=10940&SEMESTER=S19 | instructors:Poczos, Barnabas description:Independent Study to be used to work on research with faculty.
